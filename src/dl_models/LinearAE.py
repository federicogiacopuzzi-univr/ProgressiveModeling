import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras import metrics
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

def create_autoencoder_model(input_dim, latent_dim):
    r"""
    Creates and compiles an autoencoder model for dimensionality reduction and data reconstruction.

    Parameters
    ----------
    - input_dim (int): The dimension of the input (number of features).
    - latent_dim (int): The dimension of the latent code (reduced dimension).

    Returns
    ----------
    - model (tensorflow.keras.Sequential): A compiled model ready for training.

    The function performs the following steps:
    1. Creates an autoencoder model with an encoder and a decoder.
    2. Uses a two-layer architecture with the specified latent dimension.
    3. Compiles the model with the Adam optimizer and MSE loss function.
    """
    # Create a Sequential model for the autoencoder
    model = models.Sequential()
    
    # Encoder
    model.add(layers.Dense(64, input_dim=input_dim, activation='relu'))  # Encoder layer 1
    model.add(layers.Dense(latent_dim, activation='relu'))  # Bottleneck (latent space)
    
    # Decoder
    model.add(layers.Dense(64, activation='relu'))  # Encoder layer 1
    model.add(layers.Dense(input_dim, activation='sigmoid'))  # Output layer (reconstruction)
    
    # Compile the model with Adam optimizer and MSE loss function
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[metrics.mae])

    return model

def Autoencoder(dataframe, features):
    r"""
    Creates and trains an autoencoder model to reduce the dimensionality of the data.

    Parameters
    ----------
    - dataframe (pandas.DataFrame): A DataFrame containing the data, including both features.
    - features (list): List of column names representing the features used as input to the autoencoder.

    Returns
    ----------
    - tuple: A tuple containing:
        - x_test (numpy.ndarray): The original test data.
        - x_pred (numpy.ndarray): The autoencoder's predictions on the test data.

    The function performs the following steps:
    1. Standardizes the features to the range [-1, 1] using MinMaxScaler.
    2. Splits the data into training and test sets.
    3. Creates and trains the autoencoder model.
    4. Returns the original test data and the predictions generated by the model.
    """
    # Initialize the dataframe
    df = dataframe.copy()

    # Standardize the features to the range [-1, 1] using MinMaxScaler
    sc = MinMaxScaler(feature_range=(-1, 1))
    
    # Iterate over the features and standardize them
    for var in features:
        df[var] = sc.fit_transform(df[var].values.reshape(-1, 1))

    # Extract the features
    X = df[features].to_numpy()

    # Split the data into training and test sets (70% training, 30% test)
    X_train, X_test = train_test_split(X, test_size=0.3, random_state=7)

    # Create the autoencoder model
    latent_dim = 20  # Set the latent dimension size
    model = create_autoencoder_model(input_dim=X_train.shape[1], latent_dim=latent_dim)

    # Train the model
    model.fit(X_train, X_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)

    # Make predictions on the test data
    x_pred = model.predict(X_test)

    return X_test, x_pred