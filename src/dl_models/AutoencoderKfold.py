import numpy as np
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import metrics
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, KFold

def create_autoencoder_model(input_dim, latent_dim):
    r"""
    Creates and compiles a linear autoencoder model for dimensionality reduction and data reconstruction.
    This model uses linear activations for both the encoder and decoder layers, except for the output layer 
    which uses a sigmoid activation to ensure that the reconstruction values are in the range [0, 1].

    Parameters
    ----------
    - input_dim (int): The dimension of the input (number of features).
    - latent_dim (int): The dimension of the latent code (reduced dimension).

    Returns
    ----------
    - model (tensorflow.keras.Sequential): A compiled model ready for training.

    The function performs the following steps:
    1. Creates an autoencoder model with an encoder and a decoder.
    2. Uses a two-layer architecture with the specified latent dimension.
    3. Compiles the model with the Adam optimizer and MSE loss function.
    """
    # Create a Sequential model for the autoencoder
    model = models.Sequential()
    
    # Encoder
    model.add(layers.Dense(512, input_dim=input_dim, activation='elu'))  # Encoder layer 1
    model.add(layers.Dense(256, activation='elu'))  # Encoder layer 2
    model.add(layers.Dense(128, activation='elu'))  # Encoder layer 3
    model.add(layers.Dense(latent_dim, activation='elu'))  # Bottleneck (latent space)
    
    # Decoder
    model.add(layers.Dense(128, activation='elu'))  # Decoder layer 1
    model.add(layers.Dense(256, activation='elu'))  # Decoder layer 2
    model.add(layers.Dense(512, activation='elu'))  # Decoder layer 3
    model.add(layers.Dense(input_dim, activation='sigmoid'))  # Output layer (reconstruction)

    optimizer = Adam(0.00007)
    
    # Compile the model with Adam optimizer and MSE loss function
    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=[metrics.mae])

    return model

def Autoencoder(features,
                dataframe = None, 
                train_df = None, 
                test_df = None,
                epochs = 100,
                latent_dim = 32,
                test_size = 0.3,
                random_state = 7,
                validation_split = None,
                batch_size = 32,
                kfold = 1
               ):
    r"""
    Creates and trains an autoencoder model to reduce the dimensionality of the data.

    Parameters
    ----------
    - features (list): List of column names representing the features used as input to the autoencoder.
    - dataframe (pandas.DataFrame): A DataFrame containing the data, including both features (optional).
    - train_df (pandas.DataFrame or None): The training dataset (optional).
    - test_df (pandas.DataFrame or None): The test dataset (optional).
    - epochs (int): The number of epochs to train the model (default=100).
    - latent_dim (int): The dimension of the latent code (default=20).
    - test_size (float): The proportion of the test set (default=0.3).
    - random_state (int): The seed for the dataset splitting (default=7).
    - validation_split (float or None): The proportion of the data to use for validation (default=None, which disables validation).
    - batch_size (int): The number of samples per gradient update during training (default=32).
    - kfold (int): Number of folds to use for K-Fold Cross Validation. 
                   If set to 1 (default), no cross-validation is performed and the function either uses
                   a train/test split or directly trains on provided datasets.
                   If greater than 1, performs K-Fold cross-validation on the full dataframe.

    Returns
    ----------
    - tuple: A tuple containing:
        - X_test (numpy.ndarray): The original test data.
        - x_pred (numpy.ndarray): The autoencoder's predictions on the test data.

    The function performs the following steps:
    1. Standardizes the features to the range [0, 1] using MinMaxScaler.
    2. Splits the data into training and test sets if no explicit train_df and test_df are provided. If these datasets are
       given, it uses them directly for training and testing.
    3. Creates and trains the autoencoder model.
    4. Returns the original test data and the predictions generated by the model.
    """
    
    # If a full dataframe is provided, scale the features and prepare data for KFold or train/test split
    if dataframe is not None:
        sc = MinMaxScaler(feature_range=(0, 1))
        dataframe[features] = sc.fit_transform(dataframe[features])
        X = dataframe[features].to_numpy()
    
    # If separate train and test dataframes are provided, scale them accordingly
    elif train_df is not None and test_df is not None:
        sc = MinMaxScaler(feature_range=(0, 1))
        train_df[features] = sc.fit_transform(train_df[features])
        test_df[features] = sc.transform(test_df[features])
        X_train = train_df[features].to_numpy()
        X_test = test_df[features].to_numpy()
    
    else:
        raise ValueError("Either a full dataframe or both train_df and test_df must be provided.")
    
    # If explicit train/test sets are given and kfold=1, train the model directly without cross-validation
    if train_df is not None and test_df is not None and kfold == 1:
        model = create_autoencoder_model(input_dim=X_train.shape[1], latent_dim=latent_dim)
        model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, verbose=1)
        x_pred = model.predict(X_test)
        return X_test, x_pred, model
    
    # If using a full dataframe and kfold > 1, perform K-Fold cross-validation
    if kfold > 1:
        kf = KFold(n_splits=kfold, shuffle=True, random_state=random_state)
        all_preds = []
        all_tests = []
    
        fold_idx = 1
        for train_index, val_index in kf.split(X):
            print(f"Fold {fold_idx}/{kfold}")
    
            # Split data for the current fold
            X_train_fold, X_val_fold = X[train_index], X[val_index]
    
            # Create and train the autoencoder model on the training fold
            model = create_autoencoder_model(input_dim=X_train_fold.shape[1], latent_dim=latent_dim)
            model.fit(
                X_train_fold, X_train_fold,
                epochs=epochs,
                batch_size=batch_size,
                verbose=1,
                validation_data=(X_val_fold, X_val_fold)
            )
    
            # Predict on the validation fold
            x_val_pred = model.predict(X_val_fold)
    
            # Store validation inputs and predictions for later analysis
            all_preds.append(x_val_pred)
            all_tests.append(X_val_fold)
    
            fold_idx += 1
    
        # Concatenate all validation data and predictions from all folds
        X_val_all = np.concatenate(all_tests, axis=0)
        preds_all = np.concatenate(all_preds, axis=0)
    
        return X_val_all, preds_all, model
    
    else:
        # If no cross-validation, split the dataframe into train/test sets and train directly
        X_train, X_test = train_test_split(X, test_size=test_size, random_state=random_state)
        model = create_autoencoder_model(input_dim=X_train.shape[1], latent_dim=latent_dim)
        model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, verbose=1)
        x_pred = model.predict(X_test)
        return X_test, x_pred, model