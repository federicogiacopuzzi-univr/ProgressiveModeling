from tensorflow.keras import layers, models, metrics
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

def create_autoencoder_model(input_dim, latent_dim):
    r"""
    Creates and compiles a linear autoencoder model for dimensionality reduction and data reconstruction.
    This model uses linear activations for both the encoder and decoder layers, except for the output layer 
    which uses a sigmoid activation to ensure that the reconstruction values are in the range [0, 1].

    Parameters
    ----------
    - input_dim (int): The dimension of the input (number of features).
    - latent_dim (int): The dimension of the latent code (reduced dimension).

    Returns
    ----------
    - model (tensorflow.keras.Sequential): A compiled model ready for training.

    The function performs the following steps:
    1. Creates an autoencoder model with an encoder and a decoder.
    2. Uses a two-layer architecture with the specified latent dimension.
    3. Compiles the model with the Adam optimizer and MSE loss function.
    """
    # Create a Sequential model for the autoencoder
    model = models.Sequential()
    
    # Encoder
    model.add(layers.Dense(64, input_dim=input_dim, activation='linear'))  # Encoder layer 1
    model.add(layers.Dense(latent_dim, activation='linear'))  # Bottleneck (latent space)
    
    # Decoder
    model.add(layers.Dense(64, activation='linear'))  # Decoder layer 1
    model.add(layers.Dense(input_dim, activation='sigmoid'))  # Output layer (reconstruction)
    
    # Compile the model with Adam optimizer and MSE loss function
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[metrics.mae])

    return model

def Autoencoder(features,
                dataframe = None, 
                train_df = None, 
                test_df = None,
                epochs = 100,
                latent_dim = 32,
                test_size = 0.3,
                random_state = 7,
                validation_split = None,
                batch_size = 32
               ):
    r"""
    Creates and trains an autoencoder model to reduce the dimensionality of the data.

    Parameters
    ----------
    - features (list): List of column names representing the features used as input to the autoencoder.
    - dataframe (pandas.DataFrame): A DataFrame containing the data, including both features (optional).
    - train_df (pandas.DataFrame or None): The training dataset (optional).
    - test_df (pandas.DataFrame or None): The test dataset (optional).
    - epochs (int): The number of epochs to train the model (default=100).
    - latent_dim (int): The dimension of the latent code (default=20).
    - test_size (float): The proportion of the test set (default=0.3).
    - random_state (int): The seed for the dataset splitting (default=7).
    - validation_split (float or None): The proportion of the data to use for validation (default=None, which disables validation).
    - batch_size (int): The number of samples per gradient update during training (default=32).

    Returns
    ----------
    - tuple: A tuple containing:
        - X_test (numpy.ndarray): The original test data.
        - x_pred (numpy.ndarray): The autoencoder's predictions on the test data.

    The function performs the following steps:
    1. Standardizes the features to the range [0, 1] using MinMaxScaler.
    2. Splits the data into training and test sets if no explicit train_df and test_df are provided. If these datasets are
       given, it uses them directly for training and testing.
    3. Creates and trains the autoencoder model.
    4. Returns the original test data and the predictions generated by the model.
    """
    
    # If df is provided, use it to create train and test splits
    if dataframe is not None:
        # Standardize the features
        sc = MinMaxScaler(feature_range=(0, 1))
        dataframe[features] = sc.fit_transform(dataframe[features])

        # Extract the features
        X = dataframe[features].to_numpy()

        # Split the data into training and test sets
        X_train, X_test = train_test_split(X, test_size=test_size, random_state=random_state)
    elif train_df is not None and test_df is not None:
        # Preprocessing for train_df and test_df
        sc = MinMaxScaler(feature_range=(0, 1))
        train_df[features] = sc.fit_transform(train_df[features])
        test_df[features] = sc.transform(test_df[features])

        X_train = train_df[features].to_numpy()
        X_test = test_df[features].to_numpy()
    else:
        raise ValueError("Either df or both train_df and test_df must be provided.")

    # Create the autoencoder model
    model = create_autoencoder_model(input_dim=X_train.shape[1], latent_dim=latent_dim)

    # Train the model
    model.fit(X_train, X_train, epochs=epochs, batch_size=batch_size, verbose=1)

    # Make predictions on the test data
    x_pred = model.predict(X_test)

    return X_test, x_pred